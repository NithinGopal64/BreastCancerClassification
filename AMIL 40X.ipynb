{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MJQjNHG9NrCV"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wutIuM_bNv3N"},"outputs":[],"source":["!cp -r ./drive/MyDrive/data_breakhis ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ibMGWH3eOzIa"},"outputs":[],"source":["!pip install tensorboardx --quiet\n","!pip install imageio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IHvTLIymNjjT"},"outputs":[],"source":["from __future__ import print_function\n","\n","import numpy as np\n","import imageio\n","import argparse\n","import torch\n","import torch.utils.data as data_utils\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from skimage import img_as_ubyte\n","\n","# from dataloader import MnistBags\n","from amil_model import Attention\n","\n","# from __future__ import print_function, division\n","import os\n","import glob\n","from PIL import Image\n","import numpy as np\n","from torchvision import datasets, transforms\n","from torchvision import models\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from amil_model import Attention\n","from patch_data1 import PatchMethod\n","from tensorboardX import SummaryWriter\n","import argparse\n","\n","# Training settings\n","# parser = argparse.ArgumentParser(description=\"Breakthis data_mynet\")\n","# parser.add_argument(\"--zoom\", help=\"zoom_level\", default=400)\n","zoom = 40\n","# parser.add_argument(\n","#     \"--epochs\",\n","#     type=int,\n","#     default=1,\n","#     metavar=\"N\",\n","#     help=\"number of epochs to train (default: 10)\",\n","# )\n","epochs = 50\n","# parser.add_argument(\n","#     \"--seed\", type=int, default=1, metavar=\"S\", help=\"random seed (default: 1)\"\n","# )\n","seed = 1\n","# parser.add_argument(\n","#     \"--no-cuda\", action=\"store_true\", default=False, help=\"disables CUDA training\"\n","# )\n","cuda = True\n","# parser.add_argument(\n","#     \"--lr\",\n","#     type=float,\n","#     default=0.0001,\n","#     metavar=\"LR\",\n","#     help=\"learning rate (default: 0.01)\",\n","# )\n","lr = 0.0001\n","# parser.add_argument(\n","#     \"--reg\", type=float, default=10e-5, metavar=\"R\", help=\"weight decay\"\n","# )\n","reg = 10e-5\n","# args = parser.parse_args()\n","# args.cuda = not args.no_cuda and torch.cuda.is_available()\n","\n","\n","\n","\n","#zoom_level_x = str(zoom)+str(\"_norm\")\n","zoom_level_x = str(zoom)\n","\n","\n","\n","print('zoom_level_{} epoch_{} learning_rate_{}'.format(\n","    zoom_level_x, epochs, lr))\n","print(epochs)\n","writer = SummaryWriter(zoom_level_x+'/runs/'+\"epoch\"+str(epochs))\n","\n","# Training settings\n","# parser = argparse.ArgumentParser(description='PyTorch MNIST bags Example')\n","# parser.add_argument('--epochs', type=int, default=1, metavar='N',\n","#                     help='number of epochs to train (default: 10)')\n","# parser.add_argument('--lr', type=float, default=0.0001, metavar='LR',\n","#                     help='learning rate (default: 0.01)')\n","# parser.add_argument('--reg', type=float, default=10e-5, metavar='R',\n","#                     help='weight decay')\n","# parser.add_argument('--target_number', type=int, default=9, metavar='T',\n","#                     help='bags have a positive labels if they contain at least one 9')\n","# parser.add_argument('--mean_bag_length', type=int, default=10, metavar='ML',\n","#                     help='average bag length')\n","# parser.add_argument('--var_bag_length', type=int, default=2, metavar='VL',\n","#                     help='variance of bag length')\n","# parser.add_argument('--num_bags_train', type=int, default=200, metavar='NTrain',\n","#                     help='number of bags in training set')\n","# parser.add_argument('--num_bags_test', type=int, default=50, metavar='NTest',\n","#                     help='number of bags in test set')\n","# parser.add_argument('--seed', type=int, default=1, metavar='S',\n","#                     help='random seed (default: 1)')\n","# parser.add_argument('--no-cuda', action='store_true', default=False,\n","#                     help='disables CUDA training')\n","\n","# args = parser.parse_args()\n","# args.cuda = not args.no_cuda and torch.cuda.is_available()\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","    print('\\nGPU is ON!')\n","\n","print('Load Train and Test Set')\n","loader_kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n","\n","# train_loader = data_utils.DataLoader(MnistBags(target_number=args.target_number,\n","#                                                mean_bag_length=args.mean_bag_length,\n","#                                                var_bag_length=args.var_bag_length,\n","#                                                num_bag=args.num_bags_train,\n","#                                                seed=args.seed,\n","#                                                train=True),\n","#                                      batch_size=1,\n","#                                      shuffle=True,\n","#                                      **loader_kwargs)\n","\n","# test_loader = data_utils.DataLoader(MnistBags(target_number=args.target_number,\n","#                                               mean_bag_length=args.mean_bag_length,\n","#                                               var_bag_length=args.var_bag_length,\n","#                                               num_bag=args.num_bags_test,\n","#                                               seed=args.seed,\n","#                                               train=False),\n","#                                     batch_size=1,\n","#                                     shuffle=False,\n","#                                     **loader_kwargs)\n","\n","# dir structure would be: data/class_name(0 and 1)/dir_containing_img/img\n","# sftp://test1@10.107.42.42/home/Drive2/amil/data\n","# /home/dipesh/test1/new_data_tree/40X\n","# /home/dipesh/126/AMIL_project/AMIL_codes/amil_model.py\n","# /home/dipesh/126/AMIL_project/\n","print(zoom_level_x)\n","data_path_train = \"data_breakhis/{}/train\".format(zoom_level_x)\n","print(data_path_train)\n","data_path_test = \"data_breakhis/{}/test\".format(zoom_level_x)\n","data = PatchMethod(root=data_path_train)\n","val_data = PatchMethod(root=data_path_test, mode='test')\n","# data = PatchMethod(root = '/Users/abhijeetpatil/Desktop/screenshots2/')\n","# val_data =PatchMethod(root = '/Users/abhijeetpatil/Desktop/screenshots2/', mode = 'test')\n","\n","train_loader = torch.utils.data.DataLoader(\n","    data, shuffle=True, num_workers=2, batch_size=1)\n","test_loader = torch.utils.data.DataLoader(\n","    val_data, shuffle=False, num_workers=2, batch_size=1)\n","\n","\n","print('Init Model')\n","model = Attention()\n","if cuda:\n","    model.cuda()\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr,\n","                       betas=(0.9, 0.999), weight_decay=reg)\n","# optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","def train(epoch):\n","    model.train()\n","    train_loss = 0.\n","    train_error = 0.\n","    correct_label_pred = 0\n","    for batch_idx, (data, label) in enumerate(train_loader):\n","        # print(\"label\",label[0][0])\n","        # print(\"label\",label[0])\n","        bag_label = label[0]\n","        if cuda:\n","            data, bag_label = data.cuda(), bag_label.cuda()\n","        data, bag_label = Variable(data), Variable(bag_label)\n","        data = data.squeeze(0)\n","\n","        optimizer.zero_grad()\n","        # calculate loss and metrics\n","        loss, _ = model.calculate_objective(data, bag_label)\n","        train_loss += loss.data[0]\n","        error, predicted_label_train = model.calculate_classification_error(\n","            data, bag_label)\n","        # print(\"bag_label,predicted_label_train\",bag_label,predicted_label_train)\n","        # print(int(bag_label) == int(predicted_label_train))\n","        correct_label_pred += (int(bag_label) == int(predicted_label_train))\n","        # exit()\n","        train_error += error\n","        # backward pass\n","        loss.backward()\n","        # step\n","        optimizer.step()\n","        # print(correct_label_pred)\n","        # print(len(train_loader))\n","        # print(batch_idx)\n","\n","    # calculate loss and error for epoch\n","    train_loss /= len(train_loader)\n","    train_error /= len(train_loader)\n","    train_acc = (1 - train_error)*100\n","\n","    writer.add_scalar('data/train_acc', train_acc, epoch)\n","    writer.add_scalar('data/train_error', train_error, epoch)\n","    writer.add_scalar('data/train_loss', train_loss, epoch)\n","\n","    result_train = 'Epoch: {}, Loss: {:.4f}, Train error: {:.4f}, Train accuracy: {:.2f}'.format(\n","        epoch, train_loss.cpu().numpy()[0], train_error, train_acc)\n","\n","    print(result_train)\n","    return result_train\n","\n","\n","def test(epoch):\n","    model.eval()\n","    test_loss = 0.\n","    test_error = 0.\n","\n","    for batch_idx, (data, label) in enumerate(test_loader):\n","        # print(label)\n","        # print((data[0].shape))\n","\n","        bag_label = label[0]\n","\n","        instance_labels = label[0]\n","        if cuda:\n","            data, bag_label = data.cuda(), bag_label.cuda()\n","        data, bag_label = Variable(data), Variable(bag_label)\n","        loss, attention_weights = model.calculate_objective(data, bag_label)\n","        test_loss += loss.data[0]\n","        error, predicted_label = model.calculate_classification_error(\n","            data, bag_label)\n","        test_error += error\n","\n","        visualization_attention(\n","            data[0], attention_weights[0], batch_idx, epoch)\n","        if batch_idx < 1:  # plot bag labels and instance labels for first 5 bags\n","            bag_level = (bag_label.cpu().data.numpy(), int(\n","                predicted_label.cpu().data.numpy()))\n","            # print(bag_level)\n","            # print(instance_labels)\n","            # visualization_attention(data[0],attention_weights[0],batch_idx,epoch)\n","            # print(\"attention_weights.shape\",attention_weights.shape)\n","            # instance_level = list(zip(instance_labels.numpy().tolist(),\n","            #                      np.round(attention_weights.cpu().data.numpy(), decimals=3).tolist()))\n","\n","            # print('\\nTrue Bag Label, Predicted Bag Label: {}\\n'\n","            #       'True Instance Labels, Attention Weights: {}'.format(bag_level, instance_level))\n","\n","    test_error /= len(test_loader)\n","    test_loss /= len(test_loader)\n","    test_acc = (1 - test_error)*100\n","\n","    writer.add_scalar('data/test_acc', test_acc, epoch)\n","    writer.add_scalar('data/test_error', test_error, epoch)\n","    writer.add_scalar('data/test_loss', test_loss, epoch)\n","    result_test = 'Epoch: {}, Loss: {:.4f}, test error: {:.4f}, test accuracy: {:.2f}'.format(\n","        epoch, test_loss.cpu().numpy()[0], test_error, test_acc)\n","    print(result_test)\n","    return result_test\n","    # print('Test Set, Loss: {:.4f}, Test error: {:.4f}'.format(test_loss.cpu().numpy()[0], test_error))\n","\n","\n","def visualization_attention(data, attention_weights, batch_idx, epoch):\n","    img_save_dir = './{}/AMIL_visualization/epoch_{}'.format(\n","        zoom_level_x, epoch)\n","    img_save_name = img_save_dir + \\\n","        '/test_epoch_{}_no_{}.png'.format(epoch, batch_idx)\n","    if not os.path.exists(img_save_dir):\n","        os.makedirs(img_save_dir)\n","\n","    data = data.cpu().data.numpy()\n","    attention_weights = attention_weights.cpu().data.numpy()\n","    # print(\"data.shape\",data.shape)\n","    # print(\"attention_weights\",attention_weights.shape)\n","    attention_weights = attention_weights/np.max(attention_weights)\n","    complete_image = np.zeros((3, 480, 700))\n","    for height_no in range(16):\n","        for width_no in range(25):\n","            complete_image[:, height_no*28:height_no*28+28, width_no*28:width_no*28 +\n","                           28] = data[height_no*25+width_no, :, :, :] * attention_weights[height_no*25+width_no]\n","    complete_image = complete_image.transpose((1, 2, 0))\n","    #print(complete_image)\n","    #img_uint8 = complete_image.astype(np.uint8)\n","    #imageio.imwrite(img_save_name, img_uint8)\n","    imageio.imwrite(img_save_name, complete_image)\n","\n","    # weighted_images_list = data * attention_weights\n","\n","\n","if __name__ == \"__main__\":\n","    # img_save_dir = './AMIL_visualization/zoom_{}/epoch_{}'.format(zoom_level_x,epoch)\n","    main_dir = \"./\" + zoom_level_x + '/'\n","    folders = [\"pt_files\", \"txt_file\"]\n","    for i in folders:\n","        if not os.path.exists(main_dir + i):\n","            os.makedirs(main_dir + i)\n","\n","    save_string = \"AMIL_Breakthis_epochs\"+str(epochs)+\"zoom\"+zoom_level_x\n","    save_name_txt = main_dir+\"txt_file/\"+save_string+\".txt\"\n","\n","    model_file = open(save_name_txt, \"w\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cYPh8JLOpZR"},"outputs":[],"source":["for epoch in range(1, epochs + 1):\n","        print('----------Start Training----------')\n","        train_result = train(epoch)\n","        print('----------Start Testing----------')\n","        test_result = test(epoch)\n","        model_file.write(test_result + '\\n')\n","        model_file.write(train_result + '\\n')\n","model_file.close()\n","torch.save(model.state_dict(), main_dir+\"pt_files/\" +\n","               save_string+\"AMIL_Breakthis_state_dict.pt\")\n","torch.save(model, main_dir+\"pt_files/\" +\n","               save_string+\"AMIL_Breakthis_model.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WT9o6Z8edE-"},"outputs":[],"source":["#rm -rf 100_norm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQIfAybmOxAy"},"outputs":[],"source":["#!unzip  /400.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-axKQ-uUStw5"},"outputs":[],"source":["#from google.colab import files\n","#files.download(\"/200_norm.zip\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yQHpvXUUdDs"},"outputs":[],"source":["!zip -r /content/40.zip /content/40"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pqTFdA5FUmjV"},"outputs":[],"source":["files.download('/content/40.zip')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.8"}},"nbformat":4,"nbformat_minor":0}